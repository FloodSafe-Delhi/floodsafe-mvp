# FloodSafe ML Service - Lightweight Deployment (FHI + Image Classification)
#
# This Dockerfile creates a lightweight image (~100MB) for:
# - FHI (Flood Hazard Index) calculation using Open-Meteo API
# - Flood image classification using TFLite Runtime (MobileNet)
#
# Features:
# - Live FHI calculation using Open-Meteo weather API (free, no auth)
# - 90 Delhi waterlogging hotspots with dynamic risk levels
# - Flood image classification (TFLite MobileNet, ~3MB model)
#
# NOT included (to keep image small):
# - GEE (Google Earth Engine)
# - TensorFlow (replaced with TFLite Runtime)
# - PyTorch
# - Geospatial libraries (GDAL, GEOS)

FROM python:3.10-slim

WORKDIR /app

# No system dependencies needed for FHI-only deployment!
# (No GDAL, GEOS, OpenGL required)

# Copy requirements first for Docker cache optimization
COPY requirements-fhi.txt .
RUN pip install --no-cache-dir -r requirements-fhi.txt

# Install TFLite Runtime for image classification (~3MB model, ~5MB runtime)
# TFLite has no executable stack issues unlike ONNX Runtime
#
# CRITICAL: Model MUST be converted with matching TensorFlow version!
# - tflite-runtime 2.14.0 supports up to FULLY_CONNECTED opcode v11
# - Model converted with TF 2.17+ produces opcode v12 (incompatible!)
# - Use scripts/convert_tf214.py to convert model with TF 2.14.x
RUN pip install --no-cache-dir tflite-runtime==2.14.0 pillow>=10.0.0

# Copy source structure
COPY src/__init__.py src/
COPY src/main_fhi.py src/

# Core config
COPY src/core/__init__.py src/core/
COPY src/core/config.py src/core/

# API layer (hotspots + image classification)
COPY src/api/__init__.py src/api/
COPY src/api/hotspots.py src/api/
COPY src/api/classify_flood.py src/api/

# Models layer (TFLite classifier)
RUN mkdir -p src/models
RUN echo '"""Models layer."""' > src/models/__init__.py
COPY src/models/tflite_flood_classifier.py src/models/

# Data layer - create minimal __init__.py that only exports FHI
RUN mkdir -p src/data
RUN echo '"""Data layer - FHI only."""' > src/data/__init__.py
RUN echo 'from .fhi_calculator import calculate_fhi_for_location, FHICalculator, get_fhi_calculator' >> src/data/__init__.py
COPY src/data/fhi_calculator.py src/data/

# Copy hotspots JSON data
COPY data/delhi_waterlogging_hotspots.json data/

# Copy TFLite model for flood classification (~3MB)
RUN mkdir -p models
COPY models/flood_classifier.tflite models/

# Create optional directories (for cache, etc.)
RUN mkdir -p /tmp/ml-cache

# Set environment variables
ENV PYTHONPATH=/app
ENV PYTHONUNBUFFERED=1
ENV GEE_ENABLED=false

# Koyeb sets PORT automatically, but default to 8002 for local testing
ENV PORT=8002

# Expose port (Koyeb uses $PORT env var)
EXPOSE 8002

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD python -c "import httpx; r = httpx.get('http://localhost:${PORT}/health'); exit(0 if r.status_code == 200 else 1)"

# Run the FHI-only application
# Note: Koyeb injects PORT env var, so use shell form to expand it
CMD uvicorn src.main_fhi:app --host 0.0.0.0 --port ${PORT}
